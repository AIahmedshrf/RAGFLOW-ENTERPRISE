# ุฏููู ุงูููุงุฐุฌ ุงููุญููุฉ - RAGFlow Enterprise

## ๐ ูุธุฑุฉ ุนุงูุฉ

ุชู ุชูููู RAGFlow Enterprise ููุนูู ูุน ููุงุฐุฌ ูุญููุฉ ุจุฏูู ุงูุญุงุฌุฉ ูุฎุฏูุงุช ุณุญุงุจูุฉ ุฎุงุฑุฌูุฉ. ูุดูู ูุฐุง:

1. **ููุงุฐุฌ ุงูุชุถููู (Embedding Models)** - ูุชุญููู ุงููุตูุต ุฅูู vectors
2. **ููุงุฐุฌ ุงููุญุงุฏุซุฉ (Chat/LLM Models)** - ููุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ
3. **ููุงุฐุฌ ุฅุนุงุฏุฉ ุงูุชุฑุชูุจ (Rerank Models)** - ูุชุญุณูู ุฏูุฉ ูุชุงุฆุฌ ุงูุจุญุซ

---

## ๐ฏ ุงูููุงุฐุฌ ุงููููููุฉ

### 1. ููุงุฐุฌ ุงูุชุถููู (Embedding Models)

#### ๐ฃ multilingual-e5-large (ุนุจุฑ TEI)

**ุงููุตู:** ูููุฐุฌ ุชุถููู ูุชุนุฏุฏ ุงููุบุงุช ูุฏุนู 100+ ูุบุฉ ุจูุง ูููุง ุงูุนุฑุจูุฉ ูุงูุฅูุฌููุฒูุฉ

**ุงูููุงุตูุงุช:**
- **Max Tokens:** 512
- **ุญุฌู Vector:** 1024 dimension
- **ุงูุฎุฏูุฉ:** Text Embeddings Inference (TEI) ูู HuggingFace
- **ุงูุจุฑูุชูููู:** OpenAI-API-Compatible
- **ุงููููุฐ:** 6380

**ููู ุชู ุงูุชูููู:**
1. ุชู ุฅุถุงูุฉ ุฎุฏูุฉ TEI ูู `docker-compose-base.yml`:
   ```yaml
   tei:
     profiles: [ cpu, gpu ]
     image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.7.2
     command: --model-id /data/multilingual-e5-large --port 80
     ports:
       - "6380:80"
     volumes:
       - ${HF_CACHE}:/data
   ```

2. ุชู ุชูุฒูู ุงููููุฐุฌ ูุญููุงู ูู `/srv/models/hf/multilingual-e5-large`

3. ุชู ุชููููู ูู RAGFlow ุนุจุฑ ุงููุงุฌูุฉ:
   - **Provider:** OpenAI-API-Compatible
   - **Model name:** multilingual-e5-large
   - **Base URL:** http://tei:80
   - **API Key:** dummy
   - **Model Type:** TEXT_EMBEDDING
   - **Max Tokens:** 512

**ุงูุงุณุชุฎุฏุงู:**
- ููุชุงุฒ ูููุณุชูุฏุงุช ูุชุนุฏุฏุฉ ุงููุบุงุช (ุนุฑุจู + ุฅูุฌููุฒู)
- ูููู RAGFlow ุชููุงุฆูุงู ุจุชูุณูู ุงููุตูุต ุงูุทูููุฉ ุฅูู chunks ุฃุตุบุฑ ูู 512 token
- ููุณุชุฎุฏู ุชููุงุฆูุงู ุนูุฏ ุฅูุดุงุก Knowledge Base

---

#### ๐ข bge-m3 (ุนุจุฑ Ollama)

**ุงููุตู:** ูููุฐุฌ ุชุถููู ุตููู ูุชูุฏู ูุฏุนู ุงููุบุงุช ุงููุชุนุฏุฏุฉ

**ุงูููุงุตูุงุช:**
- **Max Tokens:** 8192
- **ุญุฌู Vector:** 1024 dimension
- **ุงูุฎุฏูุฉ:** Ollama
- **ุงูุญุฌู:** 1.2 GB

**ููู ุชู ุงูุชูููู:**
1. ุชู ุชูุฒูู ุงููููุฐุฌ ุนุจุฑ Ollama:
   ```bash
   ollama pull bge-m3
   ```

2. ุชู ุฅุถุงูุชู ูู RAGFlow ุนุจุฑ ุงููุงุฌูุฉ:
   - **Provider:** Ollama
   - **Model name:** bge-m3
   - **Model Type:** TEXT_EMBEDDING
   - **Max Tokens:** 8192

**ุงูุงุณุชุฎุฏุงู:**
- ูุฏุนู ูุตูุต ุฃุทูู (8192 token)
- ููุชุงุฒ ูููุณุชูุฏุงุช ุงูุทูููุฉ
- ุฃุฏุงุก ุฌูุฏ ูุน ุงููุบุฉ ุงูุตูููุฉ ูุงูุนุฑุจูุฉ

---

#### ๐ต nomic-embed-text (ุนุจุฑ Ollama)

**ุงููุตู:** ูููุฐุฌ ุชุถููู ุฎููู ูุณุฑูุน

**ุงูููุงุตูุงุช:**
- **Max Tokens:** 8192
- **ุญุฌู Vector:** 768 dimension
- **ุงูุฎุฏูุฉ:** Ollama
- **ุงูุญุฌู:** 274 MB

**ููู ุชู ุงูุชูููู:**
1. ุชู ุชูุฒููู ุนุจุฑ Ollama:
   ```bash
   ollama pull nomic-embed-text
   ```

2. ุชู ุฅุถุงูุชู ูู RAGFlow ุนุจุฑ ุงููุงุฌูุฉ:
   - **Provider:** Ollama
   - **Model name:** nomic-embed-text
   - **Model Type:** TEXT_EMBEDDING
   - **Max Tokens:** 8192

**ุงูุงุณุชุฎุฏุงู:**
- ุณุฑูุน ูุฎููู ุนูู ุงูููุงุฑุฏ
- ุฌูุฏ ูููุตูุต ุงูุฅูุฌููุฒูุฉ
- ุฃุฏุงุก ูุชูุณุท ูุน ุงููุบุฉ ุงูุนุฑุจูุฉ

---

### 2. ููุงุฐุฌ ุงููุญุงุฏุซุฉ (Chat Models)

#### ๐ด qwen2:7b-instruct (ุนุจุฑ Ollama)

**ุงููุตู:** ูููุฐุฌ ูุญุงุฏุซุฉ ุตููู ูุชูุฏู ูู Alibaba

**ุงูููุงุตูุงุช:**
- **Context Window:** 32768 tokens
- **Max Output Tokens:** 4096 (ููุตู ุจู)
- **ุงูุฎุฏูุฉ:** Ollama
- **ุงูุญุฌู:** 4.4 GB
- **Parameters:** 7 billion

**ููู ุชู ุงูุชูููู:**
1. ุชู ุชูุฒููู ุนุจุฑ Ollama:
   ```bash
   ollama pull qwen2:7b-instruct
   ```

2. ุชู ุฅุถุงูุชู ูู RAGFlow:
   - **Provider:** Ollama
   - **Model name:** qwen2:7b-instruct
   - **Model Type:** CHAT
   - **Max Tokens:** 4096

**ุงูุงุณุชุฎุฏุงู:**
- ููุชุงุฒ ููุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ ุงููุนูุฏุฉ
- ูุฏุนู ุงูุนุฑุจูุฉ ูุงูุฅูุฌููุฒูุฉ ูุงูุตูููุฉ
- context window ูุจูุฑ (32K) ูุชูุญ ุงุณุชุฎุฏุงู ูุนูููุงุช ูุซูุฑุฉ ูู ุงููุณุชูุฏุงุช

---

#### ๐ llama3:8b (ุนุจุฑ Ollama)

**ุงููุตู:** ูููุฐุฌ Meta ุงูุดููุฑ ูููุญุงุฏุซุฉ

**ุงูููุงุตูุงุช:**
- **Context Window:** 8192 tokens
- **Max Output Tokens:** 2048 (ููุตู ุจู)
- **ุงูุฎุฏูุฉ:** Ollama
- **ุงูุญุฌู:** 4.7 GB
- **Parameters:** 8 billion

**ููู ุชู ุงูุชูููู:**
1. ุชู ุชูุฒููู ูุณุจูุงู:
   ```bash
   ollama pull llama3:8b
   ```

2. ูููู ุฅุถุงูุชู ูู RAGFlow:
   - **Provider:** Ollama
   - **Model name:** llama3:8b
   - **Model Type:** CHAT
   - **Max Tokens:** 2048

**ุงูุงุณุชุฎุฏุงู:**
- ุฃุฏุงุก ููุชุงุฒ ูุน ุงููุบุฉ ุงูุฅูุฌููุฒูุฉ
- ุฃุฏุงุก ุฌูุฏ ูุน ุงููุบุฉ ุงูุนุฑุจูุฉ
- ููุซูู ูุณุฑูุน

---

#### ๐ก qwen2.5:0.5b (ุนุจุฑ Ollama)

**ุงููุตู:** ูููุฐุฌ ูุญุงุฏุซุฉ ุตุบูุฑ ูุณุฑูุน ุฌุฏุงู

**ุงูููุงุตูุงุช:**
- **Context Window:** 32768 tokens
- **Max Output Tokens:** 2048 (ููุตู ุจู)
- **ุงูุฎุฏูุฉ:** Ollama
- **ุงูุญุฌู:** 397 MB
- **Parameters:** 500 million

**ุงูุงุณุชุฎุฏุงู:**
- ุฎููู ุฌุฏุงู ุนูู ุงูููุงุฑุฏ
- ุณุฑูุน ูู ุงูุงุณุชุฌุงุจุฉ
- ููุงุณุจ ููุฃุณุฆูุฉ ุงูุจุณูุทุฉ

---

### 3. ููุงุฐุฌ ุฅุนุงุฏุฉ ุงูุชุฑุชูุจ (Rerank Models)

#### ๐ฃ BAAI/bge-reranker-v2-m3 (ูุญูู)

**ุงููุตู:** ูููุฐุฌ ุฅุนุงุฏุฉ ุชุฑุชูุจ ูุชูุฏู ูุชุญุณูู ุฏูุฉ ูุชุงุฆุฌ ุงูุจุญุซ

**ุงูููุงุตูุงุช:**
- **Max Tokens:** 8192
- **ุงูุฎุฏูุฉ:** Python FastAPI ูุญูู
- **ุงููููุฐ:** 8000
- **ุงูุจุฑูุชูููู:** OpenAI-compatible

**ููู ุชู ุงูุชูููู:**

#### ๐ง ุงูุฎุทูุงุช ุงูุชูููุฉ:

**1. ุฅูุดุงุก Dockerfile ููุฎุฏูุฉ:**

ุชู ุฅูุดุงุก `docker/rerank/Dockerfile`:
```dockerfile
FROM python:3.10-slim
WORKDIR /app
RUN pip install torch transformers sentence-transformers fastapi uvicorn
COPY app.py /app/
ENV RERANK_MODEL=BAAI/bge-reranker-v2-m3
CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]
```

**2. ุฅูุดุงุก API Server:**

ุชู ุฅูุดุงุก `docker/rerank/app.py` ูุน endpoints:
- `GET /v1/health` - ููุชุญูู ูู ุตุญุฉ ุงูุฎุฏูุฉ
- `POST /v1/rerank` - ูุฅุนุงุฏุฉ ุชุฑุชูุจ ุงููุชุงุฆุฌ

**3. ุฅุถุงูุฉ ุงูุฎุฏูุฉ ูู docker-compose-base.yml:**

```yaml
rerank:
  profiles: [ cpu, gpu ]
  build:
    context: ./rerank
  image: local-reranker:latest
  container_name: docker-rerank-1
  ports:
    - "8000:8000"  # โ ุชู ุฅุถุงูุฉ ูุฐุง ููุดุฑ ุงููููุฐ
  environment:
    - RERANK_MODEL=BAAI/bge-reranker-v2-m3
  networks: [ ragflow ]
  healthcheck:
    test: ["CMD-SHELL", "python3 -c 'import urllib.request; urllib.request.urlopen(\"http://localhost:8000/v1/health\")' || exit 1"]
    interval: 15s
    timeout: 5s
    retries: 30
  restart: on-failure
```

**ุงูุชุบููุฑุงุช ุงููููุฉ:**
- โ ุฅุถุงูุฉ `ports: - "8000:8000"` ููุดุฑ ุงููููุฐ
- โ ุชุญุฏูุซ healthcheck ููุณุชุฎุฏู Python ุจุฏูุงู ูู curl (ุบูุฑ ูุชููุฑ ูู ุงูุตูุฑุฉ)
- โ ุชู ุญุฐู `HF_HUB_ENABLE_HF_TRANSFER=1` ูุชุฌูุจ ุฃุฎุทุงุก ุงูููุชุจุงุช ุงูููููุฏุฉ

**4. ุจูุงุก ูุชุดุบูู ุงูุฎุฏูุฉ:**

```bash
cd /srv/projects/RAGFLOW-ENTERPRISE/docker
docker compose --profile cpu build rerank
docker compose --profile cpu up -d rerank
```

**5. ุงูุชุญูู ูู ุชุดุบูู ุงูุฎุฏูุฉ:**

```bash
# ูุญุต ุญุงูุฉ ุงูุฎุฏูุฉ
docker ps --filter "name=rerank"

# ุงุฎุชุจุงุฑ API
curl http://localhost:8000/v1/health
# ุงููุงุชุฌ: {"status":"ok","model":"BAAI/bge-reranker-v2-m3"}
```

**6. ุฅุถุงูุฉ ุงููููุฐุฌ ูู RAGFlow:**

ุนุจุฑ ุงููุงุฌูุฉ: **Model Providers โ OpenAI-API-Compatible โ Add Model**

```yaml
Provider: OpenAI-API-Compatible
Model name: BAAI/bge-reranker-v2-m3
Base URL: http://rerank:8000
API Key: dummy  (ุฃู ูุงุฑุบ)
Model Type: RERANK
Max Tokens: 8192
```

**๐ ููุงุญุธุฉ ูููุฉ:**
- ูู **ุฏุงุฎู Docker network**: ุงุณุชุฎุฏู `http://rerank:8000`
- ูู **ุฎุงุฑุฌ Docker** (ููุงุฎุชุจุงุฑ): ุงุณุชุฎุฏู `http://localhost:8000`

**ุงูุงุณุชุฎุฏุงู:**
- ูุนูู ุชููุงุฆูุงู ูู ุงูุฎูููุฉ ุนูุฏ ุงุณุชุฎุฏุงู RAGFlow
- ูุนูุฏ ุชุฑุชูุจ ุงููุชุงุฆุฌ ุงููุณุชุฑุฌุนุฉ ูุชุญุณูู ุงูุฏูุฉ
- ูุธูุฑ ูู **Set default models** ุจุนุฏ ุฅุถุงูุชู ูู Model Providers

**ุงุฎุชุจุงุฑ ูุฏูู:**

```bash
curl -X POST http://localhost:8000/v1/rerank \
  -H "Content-Type: application/json" \
  -d '{
    "model": "BAAI/bge-reranker-v2-m3",
    "query": "ูุง ูู ุงูุชุนูู ุงูุนูููุ",
    "documents": [
      "ุงูุชุนูู ุงูุนููู ูู ูุฑุน ูู ุงูุฐูุงุก ุงูุงุตุทูุงุนู",
      "ุงูุจูุชุฒุง ุทุนุงู ูุฐูุฐ",
      "ุงูุดุจูุงุช ุงูุนุตุจูุฉ ุชุณุชุฎุฏู ูู ุงูุชุนูู ุงูุนููู"
    ]
  }'
```

---

## ๐ ุฎุทูุงุช ุงูุฅุนุฏุงุฏ ุงููุงููุฉ

### 1. ุชุซุจูุช Ollama ูููุงุฐุฌู

```bash
# ุชุซุจูุช Ollama
curl -fsSL https://ollama.com/install.sh | sh

# ุชูุฒูู ููุงุฐุฌ Embedding
ollama pull bge-m3
ollama pull nomic-embed-text

# ุชูุฒูู ููุงุฐุฌ Chat
ollama pull qwen2:7b-instruct
ollama pull llama3:8b
ollama pull qwen2.5:0.5b

# ุงูุชุญูู ูู ุงูููุงุฐุฌ
ollama list
```

### 2. ุชูุฒูู ูููุฐุฌ multilingual-e5-large

```bash
# ุชุซุจูุช huggingface-cli
pip install huggingface-hub

# ุชูุฒูู ุงููููุฐุฌ
huggingface-cli download intfloat/multilingual-e5-large \
  --local-dir /srv/models/hf/multilingual-e5-large \
  --local-dir-use-symlinks False
```

### 3. ุชุดุบูู RAGFlow ูุน ุฌููุน ุงูุฎุฏูุงุช

```bash
cd /srv/projects/RAGFLOW-ENTERPRISE/docker

# ุชุดุบูู ุฌููุน ุงูุฎุฏูุงุช
docker compose --profile cpu up -d

# ุงูุชุญูู ูู ุงูุฎุฏูุงุช
docker compose ps
```

### 4. ุฅุถุงูุฉ ุงูููุงุฐุฌ ุนุจุฑ ูุงุฌูุฉ RAGFlow

1. ุงูุชุญ ุงููุชุตูุญ: http://localhost:8080
2. ุงุฐูุจ ุฅูู **User Settings โ Model Providers**
3. ุฃุถู ูู ูููุฐุฌ ุญุณุจ ุงูุฌุฏุงูู ุฃุนูุงู

---

## ๐ ููุงุฑูุฉ ุงูููุงุฐุฌ

### ููุงุฐุฌ ุงูุชุถููู (Embedding)

| ุงููููุฐุฌ | Max Tokens | ุญุฌู Vector | ุงููุบุงุช | ุงูุญุฌู | ุงูุณุฑุนุฉ | ุงูุฏูุฉ |
|---------|-----------|-----------|--------|-------|--------|-------|
| multilingual-e5-large | 512 | 1024 | 100+ | - | ูุชูุณุท | โญโญโญโญโญ |
| bge-m3 | 8192 | 1024 | ูุชุนุฏุฏ | 1.2GB | ุณุฑูุน | โญโญโญโญโญ |
| nomic-embed-text | 8192 | 768 | EN | 274MB | ุณุฑูุน ุฌุฏุงู | โญโญโญโญ |

### ููุงุฐุฌ ุงููุญุงุฏุซุฉ (Chat)

| ุงููููุฐุฌ | Context | Max Output | ุงูุญุฌู | ุงููุบุงุช | ุงูุฃุฏุงุก |
|---------|---------|-----------|-------|--------|--------|
| qwen2:7b-instruct | 32K | 4096 | 4.4GB | ูุชุนุฏุฏ | โญโญโญโญโญ |
| llama3:8b | 8K | 2048 | 4.7GB | EN/AR | โญโญโญโญโญ |
| qwen2.5:0.5b | 32K | 2048 | 397MB | ูุชุนุฏุฏ | โญโญโญ |

---

## ๐ ุงุณุชูุดุงู ุงูุฃุฎุทุงุก

### ุฎุฏูุฉ TEI ูุง ุชุนูู

```bash
# ูุญุต ุงูุณุฌูุงุช
docker logs docker-tei-cpu-1

# ุฅุนุงุฏุฉ ุงูุชุดุบูู
docker compose --profile cpu restart tei
```

### ุฎุฏูุฉ Rerank unhealthy

```bash
# ูุญุต ุงูุญุงูุฉ
docker ps --filter "name=rerank"

# ุงุฎุชุจุงุฑ API
curl http://localhost:8000/v1/health

# ุฅุนุงุฏุฉ ุงูุจูุงุก ูุงูุชุดุบูู
docker compose --profile cpu build rerank
docker compose --profile cpu up -d rerank
```

### Ollama ูุง ูุณุชุฌูุจ

```bash
# ุฅุนุงุฏุฉ ุชุดุบูู Ollama
systemctl restart ollama

# ูุญุต ุงูุญุงูุฉ
ollama list
```

---

## ๐ ููุงุญุธุงุช ูููุฉ

1. **Max Tokens ููู Embedding Models:**
   - ูู ุญุฏ ุงููุต ุงูููุฏุฎู ููุชุถููู
   - RAGFlow ููุณูู ุงููุตูุต ุชููุงุฆูุงู ุฅุฐุง ุชุฌุงูุฒุช ุงูุญุฏ

2. **Max Tokens ููู Chat Models:**
   - Context Window: ูู ูููู ูููููุฐุฌ ูุฑุงุกุชู
   - Max Output: ูู ูููู ูููููุฐุฌ ูุชุงุจุชู ูู ุงูุฅุฌุงุจุฉ

3. **Rerank Model:**
   - ูุนูู ุชููุงุฆูุงู ูู ุงูุฎูููุฉ
   - ูุง ูุญุชุงุฌ ุฅุนุฏุงุฏุงุช ุฅุถุงููุฉ ุจุนุฏ ุฅุถุงูุชู

4. **ุงูููุงุฐุฌ ุงููุญููุฉ:**
   - ุฌููุน ุงูููุงุฐุฌ ุชุนูู ูุญููุงู (offline)
   - ูุง ุชุญุชุงุฌ ุฅูู ุงุชุตุงู ุจุงูุฅูุชุฑูุช ุจุนุฏ ุงูุชูุฒูู
   - ูุง ุชูุฌุฏ ุชูุงููู API

---

## ๐ฏ ุงูุชูุตูุงุช

**ููุงุณุชุฎุฏุงู ุงููููู:**
- **Embedding:** multilingual-e5-large (ููุฏูุฉ) ุฃู bge-m3 (ูููุตูุต ุงูุทูููุฉ)
- **Chat:** qwen2:7b-instruct (ุงูุฃูุถู ููุบุฉ ุงูุนุฑุจูุฉ)
- **Rerank:** BAAI/bge-reranker-v2-m3 (ุถุฑูุฑู ูุชุญุณูู ุงูุฏูุฉ)

**ููุงุฎุชุจุงุฑ ุงูุณุฑูุน:**
- **Embedding:** nomic-embed-text
- **Chat:** qwen2.5:0.5b

---

## ๐ ุงูุฏุนู

ูููุฒูุฏ ูู ุงููุนูููุงุช:
- **RAGFlow Docs:** https://ragflow.io/docs
- **HuggingFace TEI:** https://github.com/huggingface/text-embeddings-inference
- **Ollama:** https://ollama.com/library

---

**ุชู ุงูุชูููู ุจูุงุณุทุฉ:** GitHub Copilot  
**ุงูุชุงุฑูุฎ:** 18 ููููุจุฑ 2025  
**ุงููุณุฎุฉ:** RAGFlow v0.21.1-slim
